{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Welcome to the OT Machine Learning Training #1\n",
    "We just heard a lot about basic ML and decision trees. Now while it is fun and challenging to code your own decision tree algo, I \n",
    "think we could better use this time to familiarize ourselves with some of the tools of the trade. This will also include \n",
    "learning about how we prepare data for ML and how tuning small parameters on the models can make a huge difference in results.\n",
    "\n",
    "So, what are these tools of the trade? Well to start, the most popular language for ML is (arguably) Python. So we will be using\n",
    "python. Don't freak out, it's pretty intuitive. \n",
    "\n",
    "What else? \n",
    "- Well we need a good way to represent and handle our data (what we will learn from). Pandas is a fantastic data analysis\n",
    "library very popular in the ML world. Pandas will allow us to read data from csv files, and represent it in a easy to handle way.\n",
    "- Since we aren't going to write our own Decision Tree right now we need a way to create one. Scikit-learn is the leading machine \n",
    "learning library in python. It provides all types of classifiers, including Decision Trees. \n",
    "- And of course this is a Jupyter notebook. It will be your favorite thing. You can execute through this notebook in parts or \n",
    "'cells' which allows you to move at your own pace and allows me to provide you some structure.\n",
    "\n",
    "The Task\n",
    "The goal of this training is to read in a 'training' dataset, use it to train a Decision Tree, and successfully classify a 'testing'\n",
    "dataset. The dataset is about the Titanic. You will be predicting whether a given person survived or not. \n",
    "The dataset source is [here](https://www.openml.org/d/40945) but you don't need to download anything.\n",
    "\n",
    "Let's get started\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is how you import libraries in python\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import tree, preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Task 1: Get Some Data\n",
    "\n",
    "Read the 'Titanic.csv' into a pandas dataframes. Change the code below to do that. If you do it right, when you run the \n",
    "notebook, it will print the dataset (you'll see passenger information etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_data = []\n",
    "print(titanic_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Task 2: Awesome you have the dataset. Now a pandas dataframe is kind of like a table. It has \n",
    "columns with labels representing our attributes, like 'age' 'sex' and 'name' and rows \n",
    "representing single instances of data. Kate Winslet would have a row, Leo would have a row etc.\n",
    "One of our attributes/columns is called 'survived'. This is what you want to teach your model \n",
    "to predict. It is our 'target class'. \n",
    "\n",
    "To use sklearn's Decision Tree, we need to separate our data into x and y. \n",
    "y will hold the target class values\n",
    "x will hold everything else\n",
    "\n",
    "Change the code below to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract the target class values from the titanic_data dataframe\n",
    "y = titanic_data['put something in here to get what you want']\n",
    "\n",
    "# now that you have separated the target class into a new variable, a copy remains in the titanic_data. Remove it so you don't have duplicates\n",
    "x = titanic_data.some_function_here_to_remove('survived', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Task 3: Great you now have x and y parts of the data. Now you need to create a training set and a testing set. The training set holds all the instances of the titanic data that your model will use to 'learn'. The testing set is what we will use to test the accuracy of your model after it has been trained. Sklearn has a nice function that seperates a dataset into x_train, x_test, y_train, y_test. Find it and change the below code to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = some_cool_function_here(x, y, train_size=0.75, test_size=0.25)\n",
    "\n",
    "# you can use this print to inspect your results\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Task 3: Awesome you have your training data, nicely seperated into instances and targets. Ready to train the tree right?? Not so\n",
    "fast. One of the tough things about sklearn and other python libraries is they don't allow for categorical variables in models. \n",
    "What does that mean? It means attributes like 'name' whose value is something other than numerical. That confuses the model and it\n",
    "will refect you. No one likes rejection. So we need to do some more data manipulating. Getting a little tedious? This is a lesson\n",
    "in ML - it's not all about the models. Having good, clean data is a huge priority and takes work. Lucky for you I'll handle this.\n",
    "Just run the below to make sure you get what you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find the offensive columns\n",
    "bad_form_attributes_train = x_train.select_dtypes(include=[object])\n",
    "bad_form_attributes_test = x_test.select_dtypes(include=[object])\n",
    "print('these are the categorical columns ', bad_form_attributes_test.columns, '\\n')\n",
    "\n",
    "# drop the badies from our nice x_train, x_test\n",
    "x_train = x_train.drop(bad_form_attributes_train.columns, axis=1)\n",
    "x_test = x_test.drop(bad_form_attributes_test.columns, axis=1)\n",
    "\n",
    "# use sklearns encoding tool to translate the categorical values into meaningful numeric ones\n",
    "encoder_train = preprocessing.LabelEncoder()\n",
    "encoded_columns_train = bad_form_attributes_train.apply(encoder_train.fit_transform)\n",
    "\n",
    "encoder_test = preprocessing.LabelEncoder()\n",
    "encoded_columns_test = bad_form_attributes_test.apply(encoder_test.fit_transform)\n",
    "print('check it out we encoded the badies \\n', encoded_columns_test)\n",
    "\n",
    "# add the now transformed categorical variables back into your dataframes\n",
    "x_train = x_train.join(encoded_columns_train, how='left', lsuffix='_left', rsuffix='_right')\n",
    "x_test = x_test.join(encoded_columns_test, how='left', lsuffix='_left', rsuffix='_right')\n",
    "print('our new, no categorical training set \\n', x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Task 3: Alright hotshot, time to create your Decision Tree. Go ahead an initialize one. Don't worry about setting any of the \n",
    "parameters right now, they all have defaults. Here's a helpful [link](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decision_tree = tree.something_here_that_makes_a_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Task 4: Alright, you think you've got your tree? Time to train it with the x_train and y_train variables you created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decision_tree = decision_tree.train_me_somehow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Task 5: Your tree is trained! Hopefully! So let's use it to predict the survival of the testingset. What you should get from using your x_test dataset is an output of 1's and 0's representing the model's guess on survival for each row in the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = decision_tree.do_something(x_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Task 6: That's awesome, you made your first predictions with a machine learning model. But its hard to really get a feel for what that means. So the model says that row x of the testing set died. Okay fine. But is it accurate? Did row x really die? Let's score the model. We have the actual answers for our testing set in y_test. Let's use them to see how you did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = decision_tree.score(x_test, y_test)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
