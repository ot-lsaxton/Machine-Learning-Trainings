{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Welcome to the OT Machine Learning Training #1\n",
    "We just heard a lot about basic ML and decision trees. Now while it is fun and challenging to code your own decision tree algo, I \n",
    "think we could better use this time to familiarize ourselves with some of the tools of the trade. This will also include \n",
    "learning about how we prepare data for ML and how tuning small parameters on the models can make a huge difference in results.\n",
    "\n",
    "So, what are these tools of the trade? Well to start, the most popular language for ML is (arguably) Python. So we will be using\n",
    "python. Don't freak out, it's pretty intuitive. \n",
    "\n",
    "What else? \n",
    "- Well we need a good way to represent and handle our data (what we will learn from). Pandas is a fantastic data analysis\n",
    "library very popular in the ML world. Pandas will allow us to read data from csv files, and represent it in a easy to handle way.\n",
    "- Since we aren't going to write our own Decision Tree right now we need a way to create one. Scikit-learn is the leading machine \n",
    "learning library in python. It provides all types of classifiers, including Decision Trees. \n",
    "- And of course this is a Jupyter notebook. It will be your favorite thing. You can execute through this notebook in parts or \n",
    "'cells' which allows you to move at your own pace and allows me to provide you some structure.\n",
    "\n",
    "The Task\n",
    "The goal of this training is to read in 'training' dataset, use it to train a Decision Tree, and successfully classify a 'test'\n",
    "dataset. The dataset is about the Titanic. You will be predicting whether a given person survived or not. \n",
    "The dataset source is [here](https://www.openml.org/d/40945) but you don't need to download anything.\n",
    "\n",
    "Let's get started\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is how you import libraries in python\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import tree, preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Task 1: Get Some Data\n",
    "\n",
    "Read the 'training.csv' and 'testing.csv' into a pandas dataframes. \n",
    "Change the code below to do that. If you do it right, when you run the \n",
    "notebook, it will print the training dataset (you'll see passenger information etc). You can\n",
    "print the testing dataset too if you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data = []\n",
    "testing_data = []\n",
    "print(training_data, '/n', testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Task 2: Awesome you have the dataset. Now a pandas dataframe is kind of like a table. It has \n",
    "columns with labels representing our attributes, like 'age' 'sex' and 'name' and rows \n",
    "representing single instances of data. Kate Winslet would have a row, Leo would have a row etc.\n",
    "One of our attributes/columns is called 'survived'. This is what you want to teach your model \n",
    "to predict. It is our 'target class'. It is okay to use these values for training, that is how\n",
    "the model learns. But if you use them for testing your model, you are 'cheating'.\n",
    "\n",
    "What we need to do is extract the 'survived' column from both datasets. The Decision tree we \n",
    "are going to use accepts two parameters to its training function: x_train and y_train \n",
    "\n",
    "When you later go to score your tree (see how well it does on unknown data) it will need a\n",
    "x_test and y_test.\n",
    "\n",
    "So:\n",
    "x_train/test is all rows and columns except the target column\n",
    "y_train/test is your target column\n",
    "\n",
    "Try to create these variables from your dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = training_data[['put something here to get what you want']]\n",
    "x_train = training_data.special_word_goes_here('survived', axis=1)\n",
    "\n",
    "y_test = testing_data[['put something here to get what you want']]\n",
    "x_test = testing_data.special_word_goes_here('survived', axis=1)\n",
    "\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Task 3: Awesome you have your training data, nicely seperated into instances and targets. Ready to train the tree right?? Not so\n",
    "fast. One of the tough things about sklearn and other python libraries is they don't allow for categorical variables in models. \n",
    "What does that mean? It means attributes like 'name' whose value is something other than numerical. That confuses the model and it\n",
    "will refect you. No one likes rejection. So we need to do some more data manipulating. Getting a little tedious? This is a lesson\n",
    "in ML - it's not all about the models. Having good, clean data is a huge priority and takes work. Lucky for you I'll handle this.\n",
    "Just run the below to make sure you get what you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find the offensive columns\n",
    "bad_form_attributes_train = x_train.select_dtypes(include=[object])\n",
    "bad_form_attributes_test = x_test.select_dtypes(include=[object])\n",
    "print('these are the categorical columns ', bad_form_attributes_test.columns, '\\n')\n",
    "\n",
    "# drop the badies from our nice x_train\n",
    "x_train = x_train.drop(bad_form_attributes_train.columns, axis=1)\n",
    "x_test = x_test.drop(bad_form_attributes_test.columns, axis=1)\n",
    "\n",
    "encoder_train = preprocessing.LabelEncoder()\n",
    "encoded_columns_train = bad_form_attributes_train.apply(encoder_train.fit_transform)\n",
    "\n",
    "encoder_test = preprocessing.LabelEncoder()\n",
    "encoded_columns_test = bad_form_attributes_test.apply(encoder_test.fit_transform)\n",
    "print('check it out we encoded the badies \\n', encoded_columns_test)\n",
    "\n",
    "x_train = x_train.join(encoded_columns_train, how='left', lsuffix='_left', rsuffix='_right')\n",
    "x_test = x_test.join(encoded_columns_test, how='left', lsuffix='_left', rsuffix='_right')\n",
    "print('our new, no categorical training set \\n', x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Task 3: Alright hotshot, time to create your Decision Tree. Go ahead an initialize one. Don't worry about setting any of the \n",
    "parameters right now, they all have defaults. Here's a helpful [link](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decision_tree = tree.something_here_that_makes_a_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Task 4: Alright, you think you've got your tree? Time to train it with the x_train and y_train variables you created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decision_tree = decision_tree.train_me_somehow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Task 5: Your tree is trained! Hopefully! So let's use it to predict the survival of the testingset. What you should get from using your x_test dataset is an output of 1's and 0's representing the model's guess on survival for each row in the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = decision_tree.do_something(x_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Task 6: That's awesome, you made your first predictions with a machine learning model. But its hard to really get a feel for what that means. So the model says that row x of the testing set died. Okay fine. But is it accurate? Did row x really die? Let's score the model. We have the actual answers for our testing set in y_test. Let's use them to see how you did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = decision_tree.score(x_test, y_test)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
